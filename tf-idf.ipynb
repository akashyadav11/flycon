{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df['sentiment'] = df['sentiment'].map({0:0,4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text'] #define all other columns except the target variable\n",
    "y = df['sentiment'] #define the target variable\n",
    "\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size = 0.02, random_state = 42)\n",
    "\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, \n",
    "                                                              test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import FeatureHasher\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_accuracy = 0\n",
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if len(x_test[y_test==0])/len(x_test)>0.5:\n",
    "        null_accuracy = len(x_test[y_test==0])/len(x_test)\n",
    "    else:\n",
    "        null_accuracy = 1 - len(x_test[y_test==0])/len(x_test)\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    report=classification_report(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Null accuracy: {0:.2f}%\".format(null_accuracy*100))\n",
    "    print(\"Accuracy: {0:.2f}%\".format(accuracy*100))\n",
    "    if accuracy>null_accuracy:\n",
    "        print(\"Model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n",
    "    elif accuracy==null_accuracy:\n",
    "        print(\"Model has the same accuracy as null accuracy\")\n",
    "    else:\n",
    "        print(\"Model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n",
    "    print(\"Train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print(\"-\"*50)\n",
    "    print(report)\n",
    "    return accuracy, train_test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "lr = LogisticRegression()\n",
    "n_features = np.arange(10000, 100001, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfeature_accuracy_checker(vectorizer = tfidf, n_features = n_features, stop_words = None, \n",
    "                              ngram_range = (1,1), classifier = lr):\n",
    "    result = []\n",
    "    print(classifier, \"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words = stop_words, max_features = n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])\n",
    "        print(\"Validation result for {0} features\".format(n))\n",
    "        nfeature_accuracy, ttime = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n",
    "        result.append((n, nfeature_accuracy, ttime))    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR UNIGRAM\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "Validation result for 10000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 79.58%\n",
      "Model is 29.39% more accurate than null accuracy\n",
      "Train and test time: 84.98s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      8013\n",
      "           1       0.79      0.80      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for 20000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 79.86%\n",
      "Model is 29.68% more accurate than null accuracy\n",
      "Train and test time: 83.25s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      8013\n",
      "           1       0.79      0.80      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for 30000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 79.90%\n",
      "Model is 29.72% more accurate than null accuracy\n",
      "Train and test time: 98.99s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      8013\n",
      "           1       0.79      0.80      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for 40000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 79.99%\n",
      "Model is 29.81% more accurate than null accuracy\n",
      "Train and test time: 101.29s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      8013\n",
      "           1       0.80      0.81      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for 50000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.05%\n",
      "Model is 29.86% more accurate than null accuracy\n",
      "Train and test time: 93.24s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      8013\n",
      "           1       0.80      0.81      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for 60000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.03%\n",
      "Model is 29.85% more accurate than null accuracy\n",
      "Train and test time: 96.67s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      8013\n",
      "           1       0.80      0.81      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for 70000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.06%\n",
      "Model is 29.87% more accurate than null accuracy\n",
      "Train and test time: 108.02s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      8013\n",
      "           1       0.80      0.81      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for 80000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.04%\n",
      "Model is 29.86% more accurate than null accuracy\n",
      "Train and test time: 99.93s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      8013\n",
      "           1       0.80      0.81      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for 90000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.11%\n",
      "Model is 29.92% more accurate than null accuracy\n",
      "Train and test time: 99.97s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      8013\n",
      "           1       0.80      0.81      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for 100000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.08%\n",
      "Model is 29.89% more accurate than null accuracy\n",
      "Train and test time: 112.20s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      8013\n",
      "           1       0.80      0.81      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Wall time: 16min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"RESULT FOR UNIGRAM\\n\")\n",
    "feature_result_ug_t = nfeature_accuracy_checker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Ridge Classifier', 'Logistic Regression', 'Perceptron', 'Passive-Agressive Classifier', 'Stochastic Gradient Descent',\n",
    "         'LinearSVC', 'L1 based LinearSVC', 'KNN', 'Nearest Centroid', 'Multinomial NB', 'Bernoulli NB', 'Adaboost']\n",
    "classifiers = [\n",
    "    RidgeClassifier(),\n",
    "    LogisticRegression(),\n",
    "    Perceptron(),\n",
    "    PassiveAggressiveClassifier(),\n",
    "    SGDClassifier(),\n",
    "    LinearSVC(),\n",
    "    Pipeline([\n",
    "        ('feature_selection', SelectFromModel(LinearSVC(penalty='l1', dual=False))),\n",
    "        ('classification', LinearSVC(penalty='l2'))\n",
    "    ]),\n",
    "    KNeighborsClassifier(),\n",
    "    NearestCentroid(),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    AdaBoostClassifier(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_clf = zip(names, classifiers)\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparator(vectorizer = tfidf, n_features=10000, stop_words=None, ngram_range=(1,1), classifier=zipped_clf):\n",
    "    result = []\n",
    "    vectorizer.set_params(stop_words=stop_words, ngram_range=ngram_range, max_features=n_features)\n",
    "    for n, c in classifier:\n",
    "        pipeline = Pipeline([('vectorizer', vectorizer), ('classifier', c)])\n",
    "        print('Validation result for {}'.format(n), c)\n",
    "        clf_accuracy, ttime = accuracy_summary(pipeline, x_train, y_train, x_validation, y_validation)\n",
    "        \n",
    "        result.append((n, clf_accuracy, ttime))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result for Ridge Classifier RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 82.29%\n",
      "Model is 32.10% more accurate than null accuracy\n",
      "Train and test time: 177.09s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      8013\n",
      "           1       0.81      0.84      0.82      7954\n",
      "\n",
      "    accuracy                           0.82     15967\n",
      "   macro avg       0.82      0.82      0.82     15967\n",
      "weighted avg       0.82      0.82      0.82     15967\n",
      "\n",
      "Validation result for Logistic Regression LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 82.43%\n",
      "Model is 32.24% more accurate than null accuracy\n",
      "Train and test time: 178.62s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      8013\n",
      "           1       0.82      0.83      0.82      7954\n",
      "\n",
      "    accuracy                           0.82     15967\n",
      "   macro avg       0.82      0.82      0.82     15967\n",
      "weighted avg       0.82      0.82      0.82     15967\n",
      "\n",
      "Validation result for Perceptron Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 76.39%\n",
      "Model is 26.20% more accurate than null accuracy\n",
      "Train and test time: 113.19s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      8013\n",
      "           1       0.76      0.76      0.76      7954\n",
      "\n",
      "    accuracy                           0.76     15967\n",
      "   macro avg       0.76      0.76      0.76     15967\n",
      "weighted avg       0.76      0.76      0.76     15967\n",
      "\n",
      "Validation result for Passive-Agressive Classifier PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
      "                            n_jobs=None, random_state=None, shuffle=True,\n",
      "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                            warm_start=False)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 79.86%\n",
      "Model is 29.68% more accurate than null accuracy\n",
      "Train and test time: 115.51s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      8013\n",
      "           1       0.80      0.79      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for Stochastic Gradient Descent SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 78.71%\n",
      "Model is 28.53% more accurate than null accuracy\n",
      "Train and test time: 111.60s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78      8013\n",
      "           1       0.78      0.80      0.79      7954\n",
      "\n",
      "    accuracy                           0.79     15967\n",
      "   macro avg       0.79      0.79      0.79     15967\n",
      "weighted avg       0.79      0.79      0.79     15967\n",
      "\n",
      "Validation result for LinearSVC LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 82.26%\n",
      "Model is 32.08% more accurate than null accuracy\n",
      "Train and test time: 838.67s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      8013\n",
      "           1       0.83      0.81      0.82      7954\n",
      "\n",
      "    accuracy                           0.82     15967\n",
      "   macro avg       0.82      0.82      0.82     15967\n",
      "weighted avg       0.82      0.82      0.82     15967\n",
      "\n",
      "Validation result for L1 based LinearSVC Pipeline(memory=None,\n",
      "         steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None,\n",
      "                                                     dual=False,\n",
      "                                                     fit_intercept=True,\n",
      "                                                     intercept_scaling=1,\n",
      "                                                     loss='squared_hinge',\n",
      "                                                     max_iter=1000,\n",
      "                                                     multi_class='ovr',\n",
      "                                                     penalty='l1',\n",
      "                                                     random_state=None,\n",
      "                                                     tol=0.0001, verbose=0),\n",
      "                                 max_features=None, norm_order=1, prefit=False,\n",
      "                                 threshold=None)),\n",
      "                ('classification',\n",
      "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                           fit_intercept=True, intercept_scaling=1,\n",
      "                           loss='squared_hinge', max_iter=1000,\n",
      "                           multi_class='ovr', penalty='l2', random_state=None,\n",
      "                           tol=0.0001, verbose=0))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 82.41%\n",
      "Model is 32.22% more accurate than null accuracy\n",
      "Train and test time: 989.29s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      8013\n",
      "           1       0.83      0.81      0.82      7954\n",
      "\n",
      "    accuracy                           0.82     15967\n",
      "   macro avg       0.82      0.82      0.82     15967\n",
      "weighted avg       0.82      0.82      0.82     15967\n",
      "\n",
      "Validation result for KNN KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 62.55%\n",
      "Model is 12.37% more accurate than null accuracy\n",
      "Train and test time: 1872.75s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.45      0.55      8013\n",
      "           1       0.59      0.80      0.68      7954\n",
      "\n",
      "    accuracy                           0.63     15967\n",
      "   macro avg       0.64      0.63      0.61     15967\n",
      "weighted avg       0.64      0.63      0.61     15967\n",
      "\n",
      "Validation result for Nearest Centroid NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 72.55%\n",
      "Model is 22.36% more accurate than null accuracy\n",
      "Train and test time: 120.74s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73      8013\n",
      "           1       0.73      0.71      0.72      7954\n",
      "\n",
      "    accuracy                           0.73     15967\n",
      "   macro avg       0.73      0.73      0.73     15967\n",
      "weighted avg       0.73      0.73      0.73     15967\n",
      "\n",
      "Validation result for Multinomial NB MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.15%\n",
      "Model is 29.97% more accurate than null accuracy\n",
      "Train and test time: 106.64s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      8013\n",
      "           1       0.81      0.79      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for Bernoulli NB BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 79.91%\n",
      "Model is 29.73% more accurate than null accuracy\n",
      "Train and test time: 106.89s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      8013\n",
      "           1       0.79      0.81      0.80      7954\n",
      "\n",
      "    accuracy                           0.80     15967\n",
      "   macro avg       0.80      0.80      0.80     15967\n",
      "weighted avg       0.80      0.80      0.80     15967\n",
      "\n",
      "Validation result for Adaboost AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 70.23%\n",
      "Model is 20.05% more accurate than null accuracy\n",
      "Train and test time: 765.85s\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68      8013\n",
      "           1       0.67      0.79      0.72      7954\n",
      "\n",
      "    accuracy                           0.70     15967\n",
      "   macro avg       0.71      0.70      0.70     15967\n",
      "weighted avg       0.71      0.70      0.70     15967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram_comparison = classifier_comparator(n_features=90000, ngram_range=(1,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
